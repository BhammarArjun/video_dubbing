# 🧩 **How the Multilingual Dubbing Pipeline Thinks**

video demo - https://drive.google.com/file/d/1rn-Uv56FF3FwM8yEWOEv5-uahPEU3qJF/view?usp=sharing

I wanted a system that turns *any* YouTube video into a natural‑sounding dub in another language while preserving each speaker’s vibe. Below is the mental wiring diagram—why each choice was made and what still hurts.

---

## 1 Gemini as the Brains of ASR

### What Gemini actually does

1. **Watches the raw YouTube URL** – Because Gemini accepts vision + audio, I skip downloading giant audio tracks.
2. **Diarises up to four main speakers (+ “Other Speakers”)** – Assigns IDs and *perceives* gender.
3. **Transcribes in the source language** – Chunked by *meaning*, not arbitrary timestamps.
4. **Translates each chunk into the target language** – While mirroring each speaker’s formality, slang, or humor.
5. **Builds a ********************************`tts_instruction_key`******************************** for every speaker** – Voice quality, tone, pacing, accent quirks, etc.
6. **Returns one strict JSON** – Keys: `speaker_profiles` and `dubbing_segments`; timestamps in MM\:SS\:mmm; durations to 3 dp.

### Why the prompt looks the way it does

* **Speaker cap** → 4 IDs keeps voice management feasible.
* **Gender tag** → Lets me map to male/female voice buckets quickly.
* **Style keys** → Without them, TTS voices sound generic.
* **Chunking rule** → “Don’t split continuous thoughts” prevents robotic mid‑sentence cuts.
* **Absolute timestamp requirement** → Crucial for later lip‑sync.

*(Full prompt lives in ****************`config/prompts.py`****************; variables stripped here for clarity.)*

---

## 2 Turning Text into Voice

1. **Voice pick** – For each chunk I look at its speaker’s gender tag and pick a GPT‑4o TTS voice from a predefined map. (Female → `nova`, `shimmer`; Male → `alloy`, `echo`.)
2. **Inject style** – The chunk text plus its `tts_instruction_key` go straight into the TTS call, so tone and pacing match the original.
3. **Speed mismatch problem** – Target language sentences almost never last the exact same time. After synthesis I measure

   ```
   ratio = len(audio) / (duration_seconds * sample_rate)
   ```

   and WSOLA‑stretch between **0.5 × and 2 ×** so the start/end align.
4. **Quality hit** – WSOLA is gentler than naïve resampling but artifacts creep in beyond ±25 %. Real fix =

   * *Voice‑to‑voice* models (clone the original voice, respect timing).
   * or **TTS with duration control** (tell the model: “Speak this in 2.37 s”).

### Why not ElevenLabs (yet)?

* It offers great cloning, but I found no reliable way to pass a full *style input + precise duration hints in one shot.*
* GPT‑4o TTS isn’t perfect, but its  input lets me stuff the entire `tts_instruction_key` directly.

### Why not Gemini TTS?

* It *can* read the same JSON and nail tone, but free‑tier rate limits stall long videos. Also still no hard duration control.

---

## 3 Merging Audio & Dealing with Background Music

* After speed‑fixing, chunk WAVs are concatenated → one dub track.
* FFmpeg replaces the original audio in the MP4.
* **Missing BGM issue:**  YouTube  streams come without the music bed. That’s okay for tutorials; bad for movies. Future plan: download separate audio‑only stream or run source‑separation, then re‑mix music under the dub.

---

## 4 Current Pain Points & Wishlist

| Pain                   | Dream Fix                                                   |
| ---------------------- | ----------------------------------------------------------- |
| Time‑stretch artifacts | Voice‑to‑voice with built‑in alignment                      |
| Lost background music  | Adaptive audio download + ducking under synthesized speech. |
| API rate limits        | Batch jobs, paid tiers, or local models.                    |

---

## 5 Roadmap of Experiments

1. Will Try out VoiceStar and Gemini TTS in future

---

## 6 Credit

* **Arjun Bhammar** – Original concept & code.
* **ChatGPT** – Scribe of these thoughts.
* **Google DeepMind & OpenAI** – The engines.

> *README auto‑generated by ChatGPT because typing Markdown bores me more than debugging FFmpeg.*
> Check run.md file to setup instructions
